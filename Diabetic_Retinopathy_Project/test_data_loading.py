#!/usr/bin/env python3
"""
Test script to verify data loading fix for MSc project
"""

import pandas as pd
import numpy as np
from pathlib import Path
import pydicom
import cv2
from PIL import Image
import matplotlib.pyplot as plt

def test_manifest_loading():
    """Test loading the complete manifest data"""
    print("ğŸ§ª TESTING MANIFEST DATA LOADING")
    print("=" * 50)
    
    # Load manifest
    manifest_path = Path('data/manifest.csv')
    if not manifest_path.exists():
        print(f"âŒ Manifest file not found at: {manifest_path}")
        return False
    
    df = pd.read_csv(manifest_path)
    print(f"âœ… Successfully loaded manifest with {len(df)} participants")
    
    # Analyze data availability
    print(f"\nğŸ“Š DATA AVAILABILITY ANALYSIS:")
    print(f"   Total participants: {len(df)}")
    print(f"   Fundus images: {df['fundus_path'].notna().sum()}")
    print(f"   OCT images: {df['oct_path'].notna().sum()}")
    print(f"   FLIO images: {df['flio_path'].notna().sum()}")
    
    # Find complete cases
    complete_cases = df.dropna()
    print(f"   Complete cases (all 3 modalities): {len(complete_cases)}")
    
    # Check for sufficient data
    if len(complete_cases) >= 50:
        print(f"âœ… Sufficient data for machine learning ({len(complete_cases)} complete cases)")
        return True
    else:
        print(f"âš ï¸ Limited complete cases ({len(complete_cases)}), but can work with partial data")
        return True

def test_dicom_loading():
    """Test loading a few DICOM images"""
    print(f"\nğŸ§ª TESTING DICOM IMAGE LOADING")
    print("=" * 45)
    
    manifest_path = Path('data/manifest.csv')
    df = pd.read_csv(manifest_path)
    
    # Test loading first few images
    test_count = 0
    success_count = 0
    
    for idx, row in df.head(10).iterrows():
        for modality in ['fundus', 'oct', 'flio']:
            file_path = row[f'{modality}_path']
            if pd.notna(file_path):
                test_count += 1
                try:
                    # Load DICOM
                    dcm = pydicom.dcmread(file_path)
                    
                    # Extract pixel data
                    if hasattr(dcm, 'pixel_array'):
                        image = dcm.pixel_array
                        
                        # Basic preprocessing
                        if image.dtype != np.uint8:
                            image = ((image - image.min()) / (image.max() - image.min()) * 255).astype(np.uint8)
                        
                        # Convert to RGB if needed
                        if len(image.shape) == 2:
                            image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
                        
                        # Resize
                        image = cv2.resize(image, (224, 224))
                        
                        success_count += 1
                        print(f"   âœ… {modality.upper()}: {Path(file_path).name}")
                    else:
                        print(f"   âŒ {modality.upper()}: No pixel data")
                        
                except Exception as e:
                    print(f"   âŒ {modality.upper()}: Error - {str(e)[:50]}...")
    
    print(f"\nğŸ“Š DICOM LOADING RESULTS:")
    print(f"   Tests attempted: {test_count}")
    print(f"   Successful loads: {success_count}")
    print(f"   Success rate: {success_count/test_count*100:.1f}%")
    
    return success_count > 0

def test_foundation_model_simulation():
    """Simulate foundation model feature extraction"""
    print(f"\nğŸ§ª TESTING FOUNDATION MODEL SIMULATION")
    print("=" * 50)
    
    # Simulate feature extraction
    n_samples = 100
    n_features = 768  # Standard foundation model feature dimension
    
    # Create simulated features for each modality
    modalities = ['fundus', 'oct', 'flio']
    features_data = {}
    
    for modality in modalities:
        # Simulate foundation model features
        features = np.random.randn(n_samples, n_features)
        labels = np.random.choice([0, 1, 2, 3, 4], size=n_samples, p=[0.3, 0.25, 0.2, 0.15, 0.1])
        
        features_data[modality] = {
            'features': features,
            'labels': labels,
            'n_samples': n_samples,
            'n_features': n_features
        }
        
        print(f"   âœ… {modality.upper()}: {n_samples} samples, {n_features} features")
    
    # Test multi-modal fusion
    print(f"\nğŸ”— TESTING MULTI-MODAL FUSION")
    print("-" * 35)
    
    # Combine features
    combined_features = []
    for modality, data in features_data.items():
        combined_features.append(data['features'])
    
    X = np.concatenate(combined_features, axis=1)
    y = features_data['fundus']['labels']  # Use fundus labels as reference
    
    print(f"   Combined shape: {X.shape}")
    print(f"   Classes: {np.unique(y)}")
    print(f"   Class distribution: {dict(zip(*np.unique(y, return_counts=True)))}")
    
    # Test train-test split
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, stratify=y, random_state=42
    )
    
    print(f"   Training samples: {len(X_train)}")
    print(f"   Test samples: {len(X_test)}")
    
    # Test model training
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.metrics import accuracy_score, f1_score
    
    model = RandomForestClassifier(n_estimators=50, random_state=42)
    model.fit(X_train, y_train)
    
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='weighted')
    
    print(f"   Model accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")
    print(f"   Model F1-score: {f1:.4f}")
    
    return True

def main():
    """Run all tests"""
    print("ğŸš€ TESTING DATA LOADING FIX FOR MSc PROJECT")
    print("=" * 60)
    
    tests = [
        ("Manifest Loading", test_manifest_loading),
        ("DICOM Loading", test_dicom_loading),
        ("Foundation Model Simulation", test_foundation_model_simulation)
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        try:
            results[test_name] = test_func()
        except Exception as e:
            print(f"âŒ {test_name} failed: {e}")
            results[test_name] = False
    
    # Summary
    print(f"\nğŸ† TEST RESULTS SUMMARY")
    print("=" * 30)
    
    passed = sum(results.values())
    total = len(results)
    
    for test_name, result in results.items():
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"   {test_name}: {status}")
    
    print(f"\nğŸ“Š OVERALL: {passed}/{total} tests passed")
    
    if passed == total:
        print("ğŸ‰ ALL TESTS PASSED! Data loading fix is working correctly.")
        print("ğŸ’¡ You can now proceed with the fixed supervised training notebook.")
    else:
        print("âš ï¸ Some tests failed. Please check the data paths and dependencies.")
    
    return passed == total

if __name__ == "__main__":
    main() 